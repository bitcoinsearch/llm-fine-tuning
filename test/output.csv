title,summary,primary_keywords,secondary_keywords
MATT: [demo] Optimistic execution of arbitrary programs,"The email discusses the complexity notation of ""O(n log n)"" and suggests that it may be incorrect. The sender proposes that it should be denoted as ""O(P + log(N))"" where P represents the size of the program and N represents the number of steps (rounded up to a power of 2). However, the recipient disagrees with this suggestion and explains that it is necessary to directly know the values of h(sub_node1) and h(sub_node2) in order to compare them to the results obtained from running the computation. Without this direct knowledge, there is a 50/50 chance of choosing the incorrect subnode, making it difficult to prove a mistake with odds of only 1/2**N.The sender suggests an alternative representation of the nodes and leaves in the program, which would make it 32B longer but would eliminate the need for h() calculations. The proposed representation includes the start_pc, start_i, start_x, end_pc, end_i, end_x, h(sub_node1), and h(sub_node2) for nodes, and start_pc, start_i, start_x, end_pc, end_i, end_x, and null for leaves.The sender also raises a concern regarding the requirement for a balanced state tree. They argue that if a balanced tree is not mandatory, then there could be multiple possible trees for the same execution trace, making it easy to hide errors where the challenger cannot find them. To address this concern, the sender suggests adding a ""start_stepcount"" and ""end_stepcount"" to enforce a balanced state tree.Additionally, the recipient points out an error in a diagram illustrating the concept of state transitions. They clarify that the second node in the diagram should read ""0|0|2 -> 0|1|4"" instead of ""0|0|2 -> 1|0|2"", matching its left child.Lastly, the sender mentions that it is presumed that the counterparty verifies their knowledge of the program, i.e., all the leaves in the contract taptree, before agreeing to the contract. The recipient agrees with this assumption and concludes the email with a casual farewell.",[],"['Subnode', 'State Transitions', 'State Tree', 'Complexity Notation', 'Optimistic Execution', 'Program Size', 'Mistake Probability', 'Contract Taptree', 'Node Representation', 'Number of Steps']"
MATT: [demo] Optimistic execution of arbitrary programs,"In this email, Johan is responding to someone named aj who pointed out a typo. Johan agrees with aj and acknowledges that it should be O(log n), where n represents the number of steps in the program. Johan explains that P doesn't matter because they never put the whole program on the blockchain; instead, they break it down into n steps. The commitment denotes only how to create the commitment.Johan goes on to explain that when they traverse the tree, the node scripts enforce that h(sub_n ode{1,2}) is consistent with the commitment in the witness. This achieves exactly what aj suggests. To achieve this, the participants agree upfront (when the contract is created) on the exact length of the trace or the depth of the tree. If the actual execution is shorter, they fill the rest with no-ops. This ensures that they know the moment the challenge protocol starts the transactions that will be played, similar to a CTV tree. If one of the participants creates a trace from a non-balanced state tree, it will be rejected by the script at that level.Johan emphasizes the importance of building the state tree in a deterministic way. They also mention that the typo has been fixed.Overall, Johan's response provides clarification and additional details about the topic being discussed.","['Package Relay', 'Libsecp256k1', 'Bitcoin Core', 'Pools', 'Assumeutxo', 'Mempool', 'FROST', 'Research', 'Libbitcoin Kernel', 'Asmap', 'Silent Payments', 'Fees', 'Stratum-V2...', 'Mining', 'P2pool', 'Privacy', 'Schnorr', 'Lightning', 'Fuzzing', 'Segwit', 'P2P']",[]
Solving CoinPool high-interactivity issue with cut-through update of Taproot leaves,"In the email, Johan suggests that OP_CHECKCONTRACTVERIFY may be able to achieve what Antoine is looking for. He provides a link to a discussion on the Bitcoin-dev mailing list for more information (https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2023-May/021719.html).Johan explains that by committing the participants' public keys and balances in the dynamic data instead of the taptree, it is possible to have a subset of online users agree to pool their aggregated balances in a new output. Meanwhile, the funds of offline users would remain inaccessible to them in a second output.To implement this, the coinpool UTXO would be spent with a transaction that has two outputs. The first output would be the ""remainder"" of the previous coinpool, representing the offline users. The second output would be the new coinpool among the online users. If an offline user comes back online and tries to double spend the UTXO, Eltoo can be used to handle the situation.This approach allows for a flexible management of funds between online and offline users, ensuring that the offline users' funds are secure and accessible when they come back online.Please note that the farewell part of the email has been ignored, as per the given rules.","['Taproot', 'UTXO', 'Eltoo']",[]
Solving CoinPool high-interactivity issue with cut-through update of Taproot leaves,"The email discusses the issue of disaggregating participant's pubkeys and balances from a partial subset push on the stack and verifying the validity of corresponding signatures. The author mentions that one requirement for a cut-through update of taproot leaves is to verify the authentication of the fan-out balances and pubkeys towards the ""online"" partition. However, this subset is not known at pool setup, even though the contract or tree construct can be equilibrated with some expectation. The author suggests that OP_CHECKCONTRACTVERIFY could be used to architect the proposed design of coinpool and its cut-through mechanism. One challenging aspect mentioned is the efficient traversal, inspection, and modification of the contract.","['Taproot', 'Update Layer']",[]
Actuarial System To Reduce Interactivity In N-of-N (N > 2) Multiparticipant Offchain Mechanisms,"The email discusses the issue of ensuring lack of equivocation in an off-chain state. The sender suggests two possible solutions for this problem: updating the subgroup of balance keys on the blockchain or designing a fraud-proof system using OP_CHECKSIGFROMSTACK and the spent outpoint committed as a partial transaction template. In order to prevent equivocation, the sender proposes using fidelity bonds that are equal to the counterparty's initial balance multiplied by the remaining counterparties. For example, if there are 1000 participants with a balance of 10,000 satoshis, each participant must lock up 10,000,000 satoshis in fidelity bonds. Only a fraction of this amount can be used as an off-chain contract or payment.The sender also mentions that a pre-nominated coordinator can reduce the burden of the full fidelity bond, but it should be considered alongside the possibility of coordinator unavailability where each participant would have to withdraw their balance on-chain and bear the fee cost.Overall, the email suggests different approaches to address the issue of equivocation in an off-chain state, emphasizing the importance of fidelity bonds and considering the role of a coordinator in reducing the burden on participants.",[],"['Fidelity bonds', 'Off-chain', 'OP_CHECKSIGFROMSTACK', 'Fraud-proof system', 'Partial transaction template', 'Equivocation', 'Coordinator']"
Solving CoinPool high-interactivity issue with cut-through update of Taproot leaves,"The email discusses the concept of using a merkle root to track participants' keys and balances in a cryptocurrency system. The sender agrees with the recipient's statement that a merkle root is needed and that scripts should enforce the creation of new merkle roots when spending the coins. The email does not provide any specific details or examples, but it highlights the importance of maintaining the integrity of the merkle root and ensuring that it aligns with the rules of the coin pool. The sender is named Johan.","['Taproot', 'Merkle Trees']",[]
Scaling Lightning With Simple Covenants,"In the email, John discusses various aspects related to Lightning network and channel resizing. He mentions that hierarchical channels can utilize HTLCs (Hashed Time-Locked Contracts) to send Lightning channel capacity over the Lightning network. This enables channel resizing off-chain between channels that are not in the same pool.John highlights an important issue regarding fragmentation costs imposed by a casual user going on-chain. He proposes a solution where the casual user pays the funder for the fragmentation costs by revealing secrets (hash preimages) known only to them. In this new version of the paper, John includes a description of how this can be done.Another point mentioned by John is the use of passive rollovers instead of active ones to eliminate the risk of HTLC-withholding attacks. Passive rollovers do not require the use of the Lightning network and are added as an advantage in the latest version of the paper.John also addresses the problem of reducing the on-chain footprint in mass exit cases. While it is listed as an open problem, he does not find any specific solutions in the referenced material. However, he introduces the concept of ""short-cut"" transactions, which are proposed to address the logarithmic blow-up of putting a control transaction defined by a covenant tree on-chain.Additionally, John clarifies that there is no case where multiple commitment transactions can spend an output from the same state transaction. Each user's state transaction can only be spent by their respective commitment transaction, and each commitment transaction requires signatures from all users involved in the hierarchical channel.In conclusion, John appreciates the recipient's effort in exploring these protocols and signs off with regards.Note: All the links provided in the original email have been retained and included as-is in the summary.","['Lightning', 'Covenants']","['Commitment Transactions', 'Fragmentation Costs', 'Short-cut Transactions', 'On-chain Footprint', 'HTLCs', 'Passive Rollovers', 'Channel Resizing']"
Draft BIP: OP_TXHASH and OP_CHECKTXHASHVERIFY,"The email discusses an update to the draft BIP (Bitcoin Improvement Proposal) that includes a proposed reference implementation and a link to an implementation of a caching strategy. The reference implementation demonstrates how it is possible to achieve TXHASH in a way that ensures invocations of TXHASH have clear constant upper limits on the number of bytes hashed, after each large transaction element (such as scripts and annexes) has been hashed exactly once.In the email, a link to the draft BIP is provided, along with another link to the cache implementation on GitHub: https://github.com/stevenroose/rust-bitcoin/blob/txhash/bitcoin/src/blockdata/script/txhash.rsThe email is from Steven Roose via the bitcoin dev mailing list, sent on 9/30/23 at 12:44.",['BIP'],['Bitcoin Improvement Proposal']
BitVM: Compute Anything on Bitcoin,"BitVM is a computing paradigm that allows for the expression of Turing-complete Bitcoin contracts without making any changes to the network's consensus rules. Instead of executing computations on Bitcoin, they are verified, similar to optimistic rollups. A prover can make a claim that a specific function evaluates to particular inputs and outputs. If this claim is false, the verifier can provide a succinct fraud proof and punish the prover.This mechanism enables the verification of any computable function on Bitcoin. However, committing to a large program in a Taproot address requires significant off-chain computation and communication. The resulting on-chain footprint, though, is minimal. Both parties involved can collaborate to perform complex, stateful off-chain computation without leaving a trace on the blockchain. On-chain execution is only necessary in the event of a dispute.To learn more about BitVM and its capabilities, refer to the official paper: https://bitvm.org/bitvm.pdf",['Taproot'],"['on-chain execution', 'off-chain computation', 'Bitcoin contracts']"
BitVM: Compute Anything on Bitcoin,"The email discusses a concept related to N-bit claims and the use of NAND circuits to determine the validity of these claims. The example provided in the email involves a 4-bit claim, where valid values take the form xxx0 and 1x01. The model described is a prover/challenger system, where the prover asserts a solution and the verifier issues challenges that the prover must consistently respond to if the solution is correct. If the prover fails to meet the challenge, they lose the funds.The circuit consists of C individual assertions, each with two inputs (selected from either the N input bits or the output of a previous assertion) and a single output. Each of these assertions is encoded as tapleafs, allowing spending a transaction via that tapleaf to validate the individual assertion. Additionally, there is an additional tapleaf per input/assertion that allows the verifier to claim the funds immediately if the prover ever provides inconsistent values for an input or the result of an assertion.If the prover attempts to cheat by claiming an invalid input, the verifier can run the circuit offline to establish the error. The email provides an example of how the verifier can trace back from the tip to identify the inconsistency. To reliably invalidate an attempt to cheat, enough challenges should be provided to cover the longest circuit path.The email also suggests that the approach of ""response enabled by challenge revealing a unique preimage"" allows for all the interesting work to be done in the witness. This means that pre-generated 2-of-2 signatures can be used to ensure protocol compliance without the need for CTV/APO. However, there would still be a need to exchange O(C*log(C)) hashes for the challenge hashes and commitment hashes.The email briefly mentions APO/CTV as a way to avoid the need for challenge hashes, but questions whether it would work effectively. It suggests using CSFS-ish behavior to make commitments by signature, eliminating the need to transfer hashes in advance.Overall, the email delves into the concept of using NAND circuits and tapleafs to validate N-bit claims, discusses the prover/challenger model, and explores potential optimizations and challenges in implementing this approach.","['Fees', 'Mining', 'Multisig', 'Script', 'Privacy', 'Lightning', 'Research', 'Hard Fork', 'Segregated Witness', 'P2P', 'Soft Fork', 'Altcoin', 'Proof-of-Work', 'Proof-of-Stake', 'Testing', 'Taproot', 'Consensus', 'Routing', 'Cryptography', 'Bitcoin Core', 'Scalability', 'Security']",[]
BitVM: Compute Anything on Bitcoin,The email from LL to Robin is requesting an example of a protocol that uses BitVM and cannot be built otherwise. LL speculates that it may involve exchanging Bitcoin with someone who can prove knowledge of an input to a binary circuit that produces a specific output.,"['Fees', 'Mining', 'Multisig', 'Privacy', 'Lightning', 'Schnorr', 'Research', 'Silent Payments', 'P2P', 'Libsecp256k1', 'Segwit', 'Libbitcoin Kernel', 'Package Relay', 'Fuzzing', 'Asmap', 'Stratum-V2', 'Pools', 'FROST', 'Bitcoin Core', 'Mempool', 'P2pool']",[]
BitVM: Compute Anything on Bitcoin,"Symphonic, I appreciate your interest in the development of arbitrary smart contracts on bitcoin. You have raised some important questions that I will address one by one.Firstly, regarding the implementation of a high-level language for these smart contracts, I am considering the possibility of either creating a new language or adapting an existing virtual machine (VM) to compile down to these scripts. This would provide developers with a more workable environment to test and experiment with these contracts. I believe many individuals would find this approach valuable.Secondly, you inquire about the computational costs associated with establishing the tapleaves for these scripts. Specifically, you are interested in whether complex operations like ECDSA signature checking can be performed feasibly. While it is a valid concern that hardware requirements may pose a barrier to widespread adoption, I aim to ensure that the technology remains accessible. However, the exact costs and feasibility depend on various factors and require further investigation.Next, you raise the question of implementing existing zero-knowledge proof (ZKP) constructs on BitVM. You suggest that using a ZKP VM to verify programs written in BitVM could simplify the verification process. This is an interesting idea and warrants exploration. Integrating ZKP constructs into BitVM could potentially enhance the security and efficiency of program verification.Lastly, you inquire about the expected costs of resolving fraud in a program. While the exact costs depend on the specific circumstances of each program, I understand your request for examples to aid comprehension. I will work on providing some simple program scenarios that illustrate how fraud resolution might unfold. This will help clarify the potential costs involved in such cases.Thank you for reaching out and raising these thought-provoking questions. Your input is valuable as it helps shape the development of this project. If you have any further inquiries or suggestions, please feel free to share them.","['Taproot', 'Bitcoin Core', 'Zero-Knowledge', 'Cryptography', 'Smart Contracts']",[]
Scaling Lightning With Simple Covenants,"The email discusses a tradeoff between trust and capital efficiency in the context of Lightning Network. The scenario presented involves a single UTXO (unspent transaction output) that can be claimed by ""B"" at a future time. However, at the current time, this UTXO holds funds belonging to both ""B"" and millions of casual users (""C_1"" through ""C_1000000"").If ""B"" cheats by not signing any further lightning updates before the claim time, each casual user would need to drop their channel to the chain or risk losing their funds. This situation leads to a ""thundering herd"" problem, where instead of the expected one-in/one-out transaction, there would be between 1 million and 2 million on-chain transactions as everyone tries to recover their funds.The impact of these additional transactions depends on the timeframe over which they occur. If spread over a day or two, it may be impossible to handle, but if spread over a year or more, it may not be noticeable. Casual users can calculate the expected number of extra transactions per block based on their factor preference. For example, if they want to ensure only 100 extra transactions per block, they can estimate the required timeout period.The email also highlights that capital efficiency is reduced when casual users follow a rollover policy and delay accessing their funds for a certain period. The total lifetime of a UTXO is split into an active lifetime (LA) and an inactive lifetime (LI). LI is typically set to 5 months, during which users would recover their funds if normal rollovers were blocked. The reduction in capital efficiency is determined by the ratio of LA to LI.Furthermore, the email notes that casual users cannot easily reduce their LI timeout by splitting into different UTXOs because cheating/failure by the provider would likely affect all their UTXOs. Collusion among different providers can also cause problems, increasing the number of transactions.To illustrate these concepts, an example is provided involving a provider with a million casual users, issuing a new UTXO every week, and targeting LA of 16 weeks. The analysis shows that only 30% of the working capital dedicated to Lightning Network routing is actually available.The email suggests possible ways to optimize capital usage, such as varying the timeout at different layers of the internal tree or peering with a dedicated node. However, these approaches may introduce additional complexity.In summary, the email raises concerns about the potential impact on-chain if the scalable path of Lightning Network fails and a large number of transactions have to be processed. It presents calculations and scenarios to measure and understand this concern.","['Lightning', 'Covenants', 'UTXO']",['Scaling']
Scaling Lightning With Simple Covenants,"The email discusses the start of a paper that presents some interesting possibilities. It mentions that the cost of enforcement is significantly increased compared to other proposals, as it involves more transactions (10+). The email also touches upon the concept of a ""dedicated user"" contributing to the expected fee, which reduces capital efficiency and raises the question of how much is enough. However, in the worst case scenario of a dramatic dedicated user failure, there would only be a 2x penalty on the number of onchain transactions, which is deemed acceptable if the network is mature enough and such failures are rare.Additionally, the email highlights the common occurrence of a ""user goes away"" case, where a casual user fails to rollover. In this case, funds would only be returned to the dedicated user. The email suggests that relying on legal and normal custody policies may be preferable in such situations, rather than burdening the UTXO (Unspent Transaction Output) set indefinitely with the current approach.Overall, the email provides an initial analysis of the paper and raises important considerations regarding the cost of enforcement, capital efficiency, and potential failure scenarios. It also emphasizes the potential benefits of relying on legal and custody policies in certain cases.","['Covenants', 'UTXO']",[]
Scaling Lightning With Simple Covenants,"In the email, John receives feedback on a proposal regarding the classification of expected users in terms of ""casual"" versus ""dedicated"" and designing protocols accordingly. The sender argues that this classification may not be so straightforward in practice, as trust assumptions in Lightning, for example, are more of a matrix than a dichotomy. There are various choices and trade-offs to consider, such as using a full-node or light client for block-relay, different mempool sizes for fee estimations, routing HTLCs, and running local watchtowers.The sender suggests introducing different scaling notions to measure the performance of off-chain constructions. These include onboarding scaling, which considers the number of users that can co-exist off-chain while considering throughput limits; transactional scaling, which focuses on the number of transfers that can be performed off-chain per on-chain transaction; and user resource scaling, which determines how much resource a user should mobilize/consume to make a trust-minimized usage of the off-chain construction.The proposal mostly focuses on onboarding scalability, maximizing the number of channels owned by a user. However, it is unclear if other scalability dimensions are being weighted. The sender mentions that no known protocol using the current Bitcoin consensus rules allows for the creation of a large number of Lightning channels from a single on-chain unspent transaction output (UTXO). They provide an example of a potential solution involving radixpool and Musig2, but acknowledge challenges with rebalancing and subranch transactions hitting the chain.The sender points out that the requirement for casual users to sign transactions specifying the exact set of casual users whose signatures are required creates a difficult group coordination problem. They mention two more precise problems related to this coordination: the dynamic novation of the group and the dynamic update of the accounts/channels owned by the users. Additionally, there is uncertainty about having a dedicated user as a gateway to route the balance and the potential for jamming, which may affect draining in the network.The sender also raises concerns about the design goal of casual users performing actions at specific times in the future. They question whether there is a guarantee that an on-chain transaction triggering the move of funds will be broadcasted by another user, especially considering mempool congestion and the need for fee risk mitigation. The meaning of ""immediately-accessible"" is also unclear in terms of confirmed or unconfirmed transactions.Lastly, the fault-tolerance of the off-chain construction is described as unclear, particularly if an unavailable or erring user causes the entire construction to end up on-chain. This is seen as a significant defect in the radixpool or old school apo channel factory.Overall, the email provides feedback and raises several questions and concerns regarding the proposed classification of users, scaling notions, group coordination, routing, and fault-tolerance in off-chain constructions.","['P2P', 'Bitcoin Core', 'Stratum-V2...', 'Package Relay', 'Assumeutxo', 'P2pool', 'Asmap', 'Mempool', 'Lightning', 'Libsecp256k1', 'Privacy', 'Fees', 'Schnorr', 'FROST', 'Research', 'Mining', 'Libbitcoin Kernel', 'Segwit', 'Silent Payments', 'Pools', 'Fuzzing']",[]
Actuarial System To Reduce Interactivity In N-of-N (N > 2) Multiparticipant Offchain Mechanisms,"The email discusses the issue of participant non-interactivity in Zeeman 40, which has halted the actuary's R reveals. The concern is that a new off-chain state, N1', with a new negotiated group of 39 participants (excluding the 40th) may reuse the R reveals on N1, which poses a security risk to the actuary bond. To address this, the suggestion is that the R reveal should only occur once all the group participants have revealed their own signatures.Furthermore, it is mentioned that there seems to be an assumption of loose interactivity, where all non-actuary participants must be online simultaneously. The lack of contribution is attributed to a ""flat"" off-chain construction without layering of promised off-chain outputs in subgroups to reduce novation interactivity.On a more fundamental level, the email points out that the actuarial system does not solve the problem of ""multi-party off-chain state correction"" as there is no guarantee that the actuary will not slash the bond itself. Additionally, if the bond is guarded by users' public keys, there is no assurance that the user will cooperate after the actuary commits equivocation and signs a ""fair"" slashing transaction.In summary, the email highlights concerns regarding participant non-interactivity, security risks to the actuary bond, the assumption of loose interactivity, the lack of multi-party off-chain state correction, and uncertainties surrounding the actuary's actions and user cooperation.","['P2P', 'Bitcoin Core', 'Stratum-V2...', 'Package Relay', 'Assumeutxo', 'P2pool', 'Asmap', 'Mempool', 'Lightning', 'Libsecp256k1', 'Privacy', 'Fees', 'Schnorr', 'FROST', 'Research', 'Mining', 'Libbitcoin Kernel', 'Segwit', 'Silent Payments', 'Pools', 'Fuzzing']",[]
"New BIP to align descriptors, xpub derivation and miniscript","Greetings Antoine,I have reviewed your email and would like to provide a detailed summary of the points you raised.Firstly, you mentioned that some wallets supporting descriptors maintain vague BIP44 compatibility. However, it is important to note that the derivation path does not ""commit to"" specific output types such as P2WSH or P2TR. The whole purpose of descriptors is to provide standardized paths for Taproot keyspend and unusual multisig P2WSH templates. It is not feasible to maintain an infinite list of BIP44 templates for all possible scripts under these output types.Moving on, you highlighted the reasons for keeping BIP44 compatibility in certain wallets. One reason is that it makes sense for some output types to remain compatible with non-descriptor wallets. For example, the Bitcoin Core wallet utilizes BIP86 for Taproot keyspend, despite being descriptor-based [0]. Additionally, some signing devices restrict the extraction of xpubs without user confirmation. This is the case with Ledger and the reason why legacy BIP48-derived paths are used in Liana.You also mentioned that using legacy standards within descriptors is pointless. While that may be true, it does not warrant the creation of another unscalable legacy standard. It is simply a matter of choosing not to use it if it can be avoided. In fact, I would suggest using `m/network'/account'//*` instead of your proposed `m/89'/network'/account'/branch//*`, if Ledger permits it.Next, you addressed the issue of reusing public keys across spending paths within a Miniscript. While it is true that you cannot reuse the same public key, you can still reuse the same signer. One approach is to derive a different hardened xpub from the signing device for each occurrence, which can be cumbersome. Alternatively, you can query a single xpub from the device and then append an unhardened derivation step. To minimize the number of steps, you can even reuse the multipath step (`xpub//*` for the first appearance, followed by `xpub//*`, `xpub//*`, and so on). Additionally, I noticed a small correction regarding the Miniscript duplicate key check. You mentioned that it does not apply under the Taproot context, but it actually does. It is important to consider that you can have multiple spending paths within a single leaf.Lastly, you mentioned that your client-side validation project introduces some ""descriptor-level concepts"" that are not covered by current standards. Instead of trying to convince existing wallets to become aware of your new standard, I would suggest fixing any incompatibilities with descriptors.Thank you for your insightful email.Best regards,Maxim[0] - Link to Bitcoin Core wallet: [insert link here]","['miniscript', 'xpub', 'BIP']","['derivation', 'descriptors']"
Trustless 2-way-peg without softfork,"In the email, Andrew is seeking a quick explanation of how a certain protocol works in a permissionless, anonymous, and decentralized manner. He specifically mentions a phrase from the protocol, ""the protocol will reach consensus on whether the state reported by the oracle is correct,"" and wants to understand its functioning along with any associated caveats.Andrew's query suggests an interest in understanding the underlying mechanism of the protocol and how it achieves consensus in a decentralized environment. Additionally, he seeks clarification on the role of oracles and their reporting of the state.To address Andrew's question, let's delve into the protocol's functioning. The protocol enables a permissionless and decentralized network where multiple participants can contribute to decision-making processes. In this context, oracles play a crucial role in providing external data or information to the network.The protocol operates based on a consensus mechanism to verify the accuracy of the information provided by the oracles. Consensus is reached when the majority of network participants validate and agree upon the state reported by the oracle. This consensus ensures that the reported state is considered correct by the protocol.It is important to note that the protocol's design emphasizes anonymity, allowing participants to engage without revealing their identities. This contributes to the decentralized nature of the network, as individuals can join and participate without needing explicit permission.Regarding caveats, the email does not provide specific details for us to address any potential limitations or risks associated with the protocol. However, it is common for decentralized systems to face challenges such as scalability, security, and reliance on trustworthy oracles. Further exploration and research may be necessary to fully understand the caveats and considerations specific to this protocol.In summary, Andrew seeks a concise explanation of how a protocol functions in a permissionless, anonymous, and decentralized manner. The protocol relies on oracles to provide information, and consensus is reached among network participants to determine the correctness of the reported state. While the email does not mention specific caveats, it is important to consider factors such as scalability, security, and reliance on trustworthy oracles in decentralized systems.","['Security', 'Consensus', 'Scalability']","['Anonymity', 'Decentralized', 'Oracles']"
Actuarial System To Reduce Interactivity In N-of-N (N > 2) Multiparticipant Offchain Mechanisms,"The email discusses the topic of loose interactivity and the need for `SIGHASH_ANYPREVOUT` in a specific context. It is mentioned that the actuary is always online and can gather signatures for the next state while signing new transactions on top of it. The purpose of `SIGHASH_ANYPREVOUT` is to allow transactions on top of the next state to spend either the actual next state or the current state plus additional transactions. This flexibility is important in case the next state fails to get fully signed and the participants decide to give up on it. There is a suggestion mentioned in the email that participants other than the actuary could generate a single public key known by all participants. However, this approach raises concerns as only one sockpuppet of the actuary would be needed to add to the participant set. The main challenge highlighted in the email is that the actuary needs to bond a significant amount of funds to each participant, which is not part of the funding of the construction.The email concludes by asking if there are any other ways to ensure single-use besides `SIGHASH_ANYPREVOUT`. The sender requests information or suggestions from the recipient regarding this matter.Note: The farewell part of the email has been ignored in the summary.","['Hard Fork', 'Multisig', 'Security', 'PSBT', 'Signet', 'Attacks', 'Lightning', 'Privacy', 'Segregated Witness', 'Fees', 'Cryptography', 'Research', 'Testing', 'Mining', 'Soft Fork', 'Consensus', 'Smart Contracts', 'Scalability', 'Routing']",[]
Concrete MATT opcodes,"There are several points discussed in the email. The sender first mentions that they are not aware of any theory regarding the cost/income structure of a lambda mining operation, as well as how changes in withhold mined coins can impact the long-term sustainability of the business. They also mention the importance of considering relationships with electricity providers and mining chip makers.Moving on, the sender agrees that if a mining operation disregards OFAC sanctioned transactions, as long as this is a minority of economic transactions, they can afford to stay in business without losing long-term blockspace issuance. However, if the cost of regulation enforcement becomes too high, they can consider moving to a jurisdiction with lower regulation costs. The sender highlights the need for further research on whether additional constructs and smart contracts would incentivize block-reorgs or transaction censoring attitudes.The email also mentions the uncertainty regarding the miners' incentives equilibrium if the timewarp attack is reduced. The sender agrees that miners and full-nodes operators' incentives should be a built-in protection in case of consensus upgrades that significantly alter the Bitcoin deep security model. However, they note that the model itself is unclear and has not been formalized despite years of blocksize wars and proposed covenant upgrades.In addition to the technical aspects, the sender raises concerns about the application of OFAC (Office of Foreign Assets Control) respecting EU GDPR (General Data Protection Regulation), Article 8 of the CEDH (European Convention on Human Rights), and constitutional protections such as Roe v. Wade in the US. They suggest that individuals with legal and technical expertise should consider opening litigations against mining pools and chain analysis companies, particularly in non-Western jurisdictions where ethical concerns may arise.The email concludes by mentioning a link to an article discussing consensus cleanup soft forks and the importance of addressing Bitcoin consensus ""technical debt"" to simplify the design and analysis of covenants and second-layer protocols.","['Mining', 'Regulation', 'Consensus', 'Smart Contracts']",[]
Concrete MATT opcodes,"Antoine is thanking Salvatore for additional insights and mentions the importance of opening Pandora's box in a sandbox to determine if it is empty. He suggests that restrictions can be added if necessary. Antoine then presents a conjecture regarding UTXO-inspecting based miners bribing contracts and proposes the idea of a ""counter-bribing"" contract that can be offered by an honest Lightning channel counterparty. He explains that UTXO-inspection can be leveraged to offer ""fee bounties"" in case a Lightning funding UTXO remains unspent after a certain period of time and there is suspicion of ongoing anomalies such as miner censorship.Antoine shares a link to a gist where he has drafted some notes on how UTXO-inspection could be used to implement an eltoo-style replacement for lightning. However, he admits that the sequence of transactions in the gist is still unclear to him. From his understanding, Alice and Bob both create virtual UTXOs, and the asymmetric update transactions are valid under the condition of spending a lower-state number virtual UTXO. Any new update transaction commits to an on-chain virtual UTXO of a higher state number. He acknowledges that this construction sounds reasonable, but believes it may be slightly less economically efficient than the original eltoo design.Antoine discusses the possibility of preventing recursive covenants that could be hijacked by censorship adversaries. He suggests that recursivity-enablement could be safeguarded using a timelock that allows escape out of the recursion after a certain number of blocks. He also mentions the idea of generalizing the index parameter so that it can refer to a group of inputs/outputs.Antoine refers to a link about ""sighash_group-like"" which talks about the use-case of non-interactive aggregation of pre-signed LN commitment transactions with a single pair of input/output. This would provide witness space efficiency benefits for LSP and Lightning nodes with hundreds of channels to be closed. He then mentions another link related to the use-case of OP_PUSH_ANNEX_TAG and wonders if a more powerful CHECKSIGFROMSTACK can be built in combination with CHECKCONTRACTVERIFY. He believes that more witness space efficiency could be achieved by casting the CCV hash as a merkle tree and traversing it.Antoine agrees that leveraging OP_CHECKSIGFROMSTACK would be more natural for enabling amount transfer validation, but acknowledges that it is less efficient in terms of witness space. He notes that the cost of this approach is O(n_outputs + n_ccv_out), where n_ccv_out is the number of executed amounts. However, he points out that its impact on spending script max opcode limits and max transaction size still needs to be evaluated.In conclusion, Antoine thanks Salvatore again and signs off as ""Best, Antoine.""","['Lightning', 'Covenants', 'Merkle Trees', 'UTXO']",[]
Trustless 2-way-peg without softfork,"The sender of the email received feedback on their proposal, which suggests that they need to create a simpler paper explaining how their proposed generic model, called ""Prometheus,"" can be applied to a specific case of two-way peg. They have planned to work on this task over the next few weeks and intend to share it with the mailing list once it is ready.","['Soft Fork', 'Trust']",[]
Bitcoin Research Day 2023,"The email announces the upcoming Bitcoin Research Day, which will be held at Chaincode in Midtown NYC on October 27th, 2023. The event aims to bring together researchers and developers to discuss the robustness, security, and decentralization of Bitcoin. It will feature both longer format talks by speakers such as Benedikt BÃ¼nz, Ethan Heilman, Ittay Eyal, Carla Kirk-Cohen, Murch, and Martin Zumsande, as well as lightning talks of approximately 5 minutes each to present ongoing research and development. Slots for the lightning talks are still available, and interested individuals can sign up using the provided link (https://www.brd23.com/lightning-talks). The organizers welcome participants from both the Bitcoin and Lightning Network communities to attend and contribute to the discussions. This is an in-person event, and RSVPs can be made through the website (https://www.brd23.com/).","['Lightning', 'Bitcoin Core', 'Research']",['Bitcoin Research Day']
Scaling Lightning With Simple Covenants,"In the email, John acknowledges aj's observation regarding the tradeoff between trust/safety and capital efficiency. He agrees with the analysis and suggests a different approach to address the issue. John proposes pairing dedicated user B with another dedicated user C, where each leaf of the timeout-tree funds a hierarchical channel. This idea is described in the ""Improving Capital Efficiency"" section of the post.John explains that if A_i (a casual user) performs an active rollover, funds not owned by A_i can always be used by B and C to route payments unrelated to the casual users in the timeout-tree. However, passive rollovers complicate this process as A_i's funds are neither definitely in the old timeout-tree nor in the new timeout-tree during the rollover. To overcome this complexity, John suggests using aj's idea of funding an HTLC from two possible sources, where one source will eventually be available to the offerer and offeree of the HTLC.By implementing this approach, B and C can utilize the funds from both the old and new timeout-trees that are not owned by A_i to route payments. If A_i puts the leaf in the old timeout-tree on-chain, B and C use funds from the new timeout-tree to fund their HTLC, and vice versa.John also expresses concern about the ""thundering herd"" problem when using hierarchical channels to improve capital efficiency. He explains that casual users may become accustomed to ever larger timeout-trees without any issues. However, if a large number of dedicated users collude by failing to roll over timeout-trees simultaneously, they could create congestion on the blockchain and potentially steal a significant portion of the casual users' funds.To address this problem, John proposes a change to the Bitcoin consensus rules. Instead of timeout-trees expiring at a specific block height, they should only expire after a sufficient number of low-fee blocks have been added to the blockchain. This way, if dedicated users attempt to steal funds by not rolling over timeout-trees, the thundering herd of transactions from casual users would push up fees, preventing the timeout-trees from expiring and safeguarding the casual users' funds.John believes that this change would deter dedicated users from attempting such thefts, as it would also result in their capital being unavailable for a longer period of time. He mentions that he is currently writing a paper and post explaining this proposal in detail.In addition to the main points discussed above, John provides a few more details about the proposed mechanism. He suggests measuring time in low-fee windows instead of counting low-fee blocks, with the window size being programmable. This makes it harder for dishonest miners to collude with dedicated users and create enough fake low-fee blocks to enable theft. It also reduces the computational cost of counting the low-fee windows. The threshold for a ""low-fee"" block can be programmable, and there is a bound on how long one waits for low-fee windows to limit storage and compute overheads. Furthermore, a similar technique supports relative delays instead of absolute delays.John concludes by stating that he believes such a mechanism would be useful in various areas, including HTLCs, and emphasizes the need for a solution like this in the context of timeout-trees.","['Lightning', 'Covenants', 'Consensus']",[]
Scaling Lightning With Simple Covenants,"In the email, John acknowledges that there is an issue regarding settling the channel on-chain and resolving HTLCS on-chain, which affects both processes. The paper mentioned in the email proposes using ""short-cut"" transactions as a solution to address the cost of enforcing HTLCs on-chain. It suggests that a similar approach could potentially be applied to the channel itself, although this would be more complex due to the value included in the channel and the possibility of having channels with different capacities in a single timeout-tree. John expresses his agreement with this idea.","['Lightning', 'Covenants']",[]
Scaling Lightning With Simple Covenants,"In this email, John responds to Antoine's previous note regarding scalability dimensions and the needs of casual users in Bitcoin. John emphasizes the importance of catering to users who simply want payments to work without having to invest time or hardware resources into it. He mentions that he has focused on providing multiple channels to as many casual users as possible.Regarding scalability, John praises Lightning for its ability to provide a large number of payments per channel without requiring on-chain transactions once the channel is created. He suggests that resizing channels can be effectively done off-chain with hierarchical channels and timeout-trees.John acknowledges the theoretical possibility of using signatures to create Lightning channels for a million casual users funded by a single UTXO, but believes it is not practical due to the challenge of getting all users to sign a transaction specifying the necessary signatures.He proposes that changing pairings should be done through the creation and expiry of timeout-trees, with users who wish to maintain the same pairing doing so via passive rollovers. He suggests that channel resizing can mainly be achieved through hierarchical channels, resorting to timeout-trees only when off-chain resizing is not possible.By implementing these proposals, John claims that interactivity can be dramatically limited. He provides an example of how at most four users would need to coordinate to update any channel, with only one being a casual user.John admits that active draining by casual users is uncertain and proposes that if the active drain fails, the casual user should put their channel in the old timeout-tree on-chain to prevent it from timing out.He acknowledges that his requirement for casual users to turn on their wallet software every few months is not ideal but believes it is better than having them perform actions within a limited time window.Addressing concerns about obtaining bitcoin if a user hasn't signed and submitted a transaction with sufficient fees, John refers to the ""Limitations"" section of his post and suggests that reliable transport mechanisms and fee timing based on fee levels could help address this issue.In case the dedicated user(s) funding a timeout-tree are unavailable or make an error, John suggests that the casual user should put their channel in the old timeout-tree on-chain. If the failure applies to all channels in the timeout-tree, the entire timeout-tree will be forced to go on-chain, potentially resulting in higher costs.John also mentions that unresolved HTLCs (Hashed Time Lock Contracts) need to be put on-chain but clarifies that doing so does not force the timeout-tree itself to go on-chain. He explains that there is a proposal in his paper for the use of ""short-cut"" transactions that may eliminate logarithmic blow-up in the number of leaves in the covenant tree when putting an HTLC transaction on-chain.In conclusion, John thanks Antoine for his thoughtful comments and invites him to reach out if there are any further clarifications needed.","['Lightning', 'Covenants']",['Scaling']
Actuarial System To Reduce Interactivity In N-of-N (N	> 2) Multiparticipant Offchain Mechanisms,"In this email, Dave raises a question about the scenario where both A and M are members of a group of thieves with control over a moderate amount of hash rate. The question is whether A can provide a ""confirmed transaction"" containing M's sign-only-once signature to B, and then generate a block before the CSV expiry that includes A's and M's signature over a different transaction that does not pay B.Dave suggests that if the CSV (Check Sequence Verify) is set for a significant amount of time in the future, the thieving group including A and M would not need to control a large amount of hash rate to have a high probability of success. This means that even if they were unsuccessful at the attempted theft, they might not lose anything and their theft attempt would be invisible to anyone outside their group.Furthermore, Dave mentions that if A is able to double spend back to herself funds that were previously intended for B, and if cut-through transactions were created where B allocated those same funds to C, the double spend would invalidate the cut-through. Therefore, Dave believes that the entire mechanism collapses into reputational trust in M, similar to the historic GreenAddress.it co-signing mechanism.It is important to note that the email does not provide any links or additional context to support these claims or provide further information.","['Consensus', 'Lightning']","['Transaction Verification', 'Double Spend']"
Actuarial System To Reduce Interactivity In N-of-N (N	> 2) Multiparticipant Offchain Mechanisms,"The email discusses the fidelity bond of M and the need to separately lock it to `(M && B) || (M && CSV(1 year))`. It mentions that the actuary would have to lock new funds before the end of the time period to prevent participants from closing the mechanism with the latest state. The bond would also have to be replicated for each participant, which reduces scalability.The sender expresses a desire to explore alternatives to the ""sign-only-once"" mechanism. They explain that they want a mechanism that allows the always-online party (referred to as the ""actuary"") to only select transactions and not move coins without consent. The closest they have come to this is in a proof-of-work blockchain, where miners can only select transactions and cannot authorize moves without owner consent.The sender concludes by stating their goal of replicating this functionality to reduce interactivity requirements, without resorting to a proof-of-work blockchain.Overall, the email raises the issue of the fidelity bond and scalability, and suggests exploring alternative mechanisms that align with the desired behavior of a proof-of-work blockchain.","['Scalability', 'Proof-of-Work']",[]
Scaling Lightning With Simple Covenants,"Based on the information provided in the email, it seems that there is a discussion about the safety of dedicated user `B` creating something without obtaining a signature from `A_i`. The author suggests that if the funding for this project comes solely from `B`, it may not be safe unless it receives a signature from `A_i`. The email mentions that if a particular `A_i` does not contact `B` but still confirms the entire path from the funding transaction output to the `A_i && B` output, the funds allocated by `B` will be locked unless `B` obtains a unilateral close signature from `A_i` to spend from `A_i && B`.The author also mentions that `A_i` needs to be online when `B` signs the funding transaction that anchors the entire tree. Failure to do so may result in the loss of funds, as seen with the implementation of `multifundchannel` by others. It is important to ensure that all counterparties in the same batch of openings have given unilateral close signatures before broadcasting the funding transaction.Another alternative discussed is infecting the leaf itself with a lifetime `(A_i && B) || (B && CLTV)`, which is described as a Spilman channel variant used in swap-in-potentiam. In this scenario, `B` can dedicate the leaf output to a separate transaction that spends from the `(A_i && B)` branch and sends to a plain `A && B` Lightning channel. `B` can fund the tree, and when `A_i` comes online and agrees to accept the channel from `B`, `A_i` creates two signatures: one for the transaction spending `(A_i && B) || (B && CLTV)` and another for the unilateral close transaction from the aforementioned output.In conclusion, this email discusses the importance of obtaining a signature from `A_i` for the safety of a project, the need for `A_i` to be online when `B` signs the funding transaction, and the alternative approach of using a Spilman channel variant.","['Signature', 'Covenants', 'Lightning']",[]
Scaling Lightning With Simple Covenants,"The email discusses a change in the trust model from trustless to a federated one, which leads to an increase in the on-chain footprint of failure. The author does not provide specific details about the context or the reasons behind this change. However, it can be inferred that the transition to a federated trust model may have implications for security and decentralization. Unfortunately, without further information, it is challenging to provide a more detailed summary.","['Covenants', 'Lightning']",[]
Scaling Lightning With Simple Covenants,"MuSig and MuSig2 are both n-of-n signing algorithms, meaning that all entities in the set, denoted as A_i for all i, and a dedicated Lightning Network (LN) node B, are involved in the signing process. This implies that the argument that 2-of-2 channels are non-custodial and trust-minimized can be extended to n-of-n for any value of n.Regards,ZmnSCPxj","['Lightning', 'Covenants', 'MuSig']",[]
Parameters in BIP21 URIs,"The email starts with a question about the conclusion of a previous discussion. The sender finds it confusing and believes that the grammar of BIP 21 (Bitcoin Improvement Proposal 21) is under specified. They suggest that each parameter should specify how many times it can be repeated. In the context of lightning, people are asking about the possibility of having multiple invoices. This makes sense because everything is encoded inside an invoice, so a person only needs to know the invoice. The sender provides a link [1] for more information on this topic.The sender expresses their preference for working on improving BIP 21, possibly with a new version where only the grammar is slightly changed. They end the email with the word ""Cheers"" and their name, Vincent.",['Lightning'],['BIP21 URIs']
Solving CoinPool high-interactivity issue with cut-through update of Taproot leaves,"The email discusses the issue of interactivity constraints in payment pools and channel factories, particularly in relation to off-chain balances. The security of user funds is crucial, and any updates to off-chain balances require unanimous agreement from all users. If a user becomes offline or unresponsive, the updates must be halted, limiting payments to subsets of two users sharing a channel. Various proposed solutions to this problem include introducing a coordinator, partitioning or layering balances among off-chain users subsets. However, these solutions introduce the issue of equivocation of off-chain balances.To mitigate equivocation, one suggestion is to punish a cheating pre-nominated coordinator through an external fidelity bond. This approach could potentially remove the need for a coordinator by implementing trust-minimized and decentralized fraud proofs. However, the punishment for equivocation should compensate the defrauded counterparty for the loss of its off-chain balance. Since a cheating counterparty can equivocate against all other counterparties, the fidelity bond should be equal to (C - 1) * B satoshi amount, where C is the number of construction counterparties and B is the initial off-chain balance of the cheating counterparty.Additionally, it is challenging to determine ahead of time which counterparties will be ""honest"" or ""dishonest"" during a partition or transition. Therefore, every counterparty in the pool or factory must maintain a fidelity bond of size (C - 1) * B. However, this mitigation, along with other corrective measures, may not be economically practical for large-scale pools involving anonymous users.The author suggests that the most realistic solution to address the interactivity issue is to prevent off-chain group equivocation proactively. They propose editing the funding utxo of the pool or factory in an efficient manner to register new off-chain subgroups as needed. One existing idea, called CoinPool, involves including a user pubkey and balance amount to each leaf composing the Taproot tree while preserving the key-path spend in case of unanimity in the user group.The author introduces a new idea, potentially called ""cut-through"" spends, where multiple leaves are updated with a single witness composed interactively by the owners of the spent leaves. This spend aggregates the amounts and user pubkeys, sending them back to a new single leaf. The user leaves not participating in this ""cut-through"" maintain their integrity in the new version of the Taproot tree without requiring interactivity from their side.The author provides an example scenario involving a CoinPool funded by Alice, Bob, Caroll, Dave, and Eve. If Bob and Eve are offline, the remaining subset (ACD group) can compose a cut-through spend. This spend generates a new leaf aggregating the amounts and pubkeys of the ACD group. Bob's and Eve's leaves remain unmodified. The ACD group can confirm a transaction spending the pool funding utxo to a new single output committing to the scriptpubkey subgroup. The known Eltoo mechanism ensures no non-observable equivocation is possible within the ACD group.Once Bob and Eve come online, they can negotiate an on-chain pool ""refresh"" transaction using the conserved key-path spend to re-equilibrate the Taproot tree, prune out old subgroups, and provision future subgroups efficiently through signature aggregation. The author mentions proposed taproot tree update script primitives that offer flexibility for generating cut-through spends or batches of cut-throughs with multiple subgroups and outputs.The author believes that such a hypothetical primitive could also reduce the chain space consumed during mass pool withdrawals. This solution shifts the burden of predicting counterparties' liveliness onto individual users, allowing them to pre-commit fast Taproot tree traversals and compose new pool subgroups based on fluctuations in liveliness. Recursive taproot tree spends or more efficient accumulators than Merkle trees are potential ideas to reduce on-chain witness space consumed by pools in the average non-interactive case.In conclusion, the email presents a solution to the interactivity issue faced by payment pools and factories by preventing off-chain group equivocation. The proposed approach involves editing the funding utxo of the pool or factory efficiently, introducing the concept of cut-through spends to update multiple leaves with a single witness. This solution requires individual users to pre-commit fast Taproot tree traversals and allows them to compose new subgroups based on liveliness predictions.","['Merkle Trees', 'Accumulators', 'Taproot']","['Eltoo Mechanism', 'Taproot Tree', 'Fidelity Bond', 'Transition', 'Payment Pools', 'Coordinator', 'Partition', 'Scriptpubkey', 'Signature Aggregation', 'CoinPool', 'Witness', 'Refresh Transaction', 'Equivocation', 'Liveliness', 'Off-chain Balances', 'Fraud Proofs', 'Chain Space', 'Cut-through', 'Channel Factories']"
Solving CoinPool high-interactivity issue with cut-through update of Taproot leaves,"Antoine receives a message from ZmnSCPxj, who asks if the term ""OP_EVICT"" is not appropriate for a certain purpose. The email does not provide any further details or context about what ""OP_EVICT"" refers to or the specific purpose in question. The email also includes a link to a web page on the Linux Foundation mailing list archive where Antoine can find more information.The email is brief and straightforward, with no additional content or questions. It is written in a professional tone and ends with ZmnSCPxj's signature and a mention of Proton Mail as the email service used.In summary, ZmnSCPxj reaches out to Antoine to inquire about the suitability of using ""OP_EVICT"" for an unknown purpose. The email lacks contextual information, but includes a link to a mailing list archive for further reference.",['Taproot'],[]
Solving CoinPool high-interactivity issue with cut-through update of Taproot leaves,"Antoine discusses the concept of OP_EVICT in the context of an off-chain payment pool. He mentions that OP_EVICT requires participant cooperation after the state update to allow a single participant to withdraw their funds. However, he believes that this approach is unsafe if they retain the security requirement that a participant should have the unilateral means to enforce the latest agreed-upon state at any time during the construction lifetime.Antoine expresses his wish for CoinPool to have a level of covenant flexibility and mentions TLUV or MERKLESUB as possible solutions. He also highlights that OP_EVICT introduces the idea of subgroup novation (K-of-N) of a PT2R scriptpubkey. However, he points out that there is currently no sound covenant proposal that combines TLUV and EVICT-like semantics in a consistent set of Script primitives to enable ""cut-through"" updates while still retaining the key property of unilateral withdrawal of promised balances in any order.Antoine expresses his interest in understanding if on-chain ""cut-through"" is the best direction to solve the fundamental high interactivity issue of channel factory and payment pool over punishment-based ideas. He mentions that he might work on crafting a proposal in the future but for now, he seeks a better understanding of the topic.Overall, Antoine's email discusses the concept of OP_EVICT in the context of an off-chain payment pool, raises concerns about its safety and proposes alternative solutions such as TLUV or MERKLESUB. He also questions the best direction to address the high interactivity issue of channel factory and payment pool.","['Taproot', 'Covenants']","['Cut-through', 'Payment pool', 'Channel factory']"
Scaling Lightning With Simple Covenants,"In the email, Antoine discusses various aspects of off-chain constructions and their efficiency considerations. He mentions that transactional scaling of Lightning, which refers to how many transfers can be performed off-chain per on-chain transaction, may face liquidity unbalance due to asymmetries in liquidity flows among counterparties. However, he notes that on-chain splicing for LSP spec upgrade improves this dimension by allowing resizing or pool rebalancing.Antoine also addresses the challenge of getting a million casual users to sign a transaction, stating that pre-committing a subset of casual or inactive users is not straightforward. He suggests the use of efficient cryptographic accumulators at the consensus level for scalability.Regarding timeout-trees and channel resizing, Antoine points out that they suffer from the lack of fault-tolerance when a casual user or end of tree balance owner wants to go on-chain. The fragmentation cost is borne by all the users located in the tree branch. He emphasizes that fault-tolerance is a key design goal for payment pool advancements over factories.Addressing the issue of performing actions within a limited time window, Antoine acknowledges that most off-chain constructions require strong liveliness and highlights TP-channel factories' novel aspect of allowing casual users to decide when they need to be on-time.The email also mentions the ""thundering herd"" problem, which is explicitly mentioned in the OG Lightning paper. Antoine states that this problem cannot be fixed by transaction-relay changes and needs separate considerations.Furthermore, Antoine discusses failures by dedicated users who can afford highly-available hardware and maintain a good reputation. He notes that once a dedicated user has many off-chain trees, they become an attack target, altering the trade-offs.Additionally, Antoine refers to the concept of ""cut-through"" to reduce on-chain footprint in mass exit cases. This concept has been discussed since the early days of off-chain constructions and is related to Taproot and Grafroot introduction.Finally, Antoine poses a couple of questions about the TP protocol's security model in scenarios involving multiple parties and commitment transactions. Specifically, he asks about preventing collusion and double-spending to protect the interests of all parties involved.Overall, Antoine's email covers various aspects of off-chain constructions, including scalability, fault-tolerance, liveliness, and security considerations.","['Lightning', 'Security', 'Scalability', 'Covenants']","['Livelihood', 'Fault-tolerance']"
Scaling Lightning With Simple Covenants,"John sent an email to ZmnSCPxj acknowledging that the design given in the figures in the paper, along with the accompanying descriptions, is correct. However, he points out that there was an error in the quoted text and agrees that it needs to be corrected. John informs ZmnSCPxj that he has created a new version of the paper [1], which includes this fix. He also mentions that the updated version provides more detail on the use of hierarchical channels during passive rollovers, specifically at the end of Section 4.9. John concludes the email by thanking ZmnSCPxj for pointing out the correction.","['Lightning', 'Covenants']",[]
MATT: [demo] Optimistic execution of arbitrary programs,"I have received an email discussing the implementation of the original MATT challenge protocol. The email includes a link to a write-up that provides a detailed description of how to transform a ""high-level arbitrary program"" into something that can be verified on-chain in Bitcoin Script. The write-up also contains instructions on running the code and inspecting the transactions using a local block explorer.The implementation utilizes the proposed opcode OP_CHECKCONTRACTVERIFY and OP_CAT. These opcodes are used to trace the execution of a program called `multiply`. The goal is to challenge the computation of this program in O(n logn) on-chain transactions.Unfortunately, the email does not provide any further details about the implementation or the specific challenges faced during the process. It mainly serves as an introduction to the topic and directs readers to the write-up for more information.[0] - Link to the original MATT challenge protocol: [insert link][1] - Link to the code for the `multiply` program: [insert link]",[],"['Opcode', 'On-chain transactions', 'Bitcoin Script']"
Draft BIP: OP_TXHASH and OP_CHECKTXHASHVERIFY,"The email is from Steven and he is discussing the concept of a TxHash (Transaction Hash) and its formalization. He has worked on a specification and has been gathering feedback for several weeks. The full BIP (Bitcoin Improvement Proposal) text can be found in the attachment and also on this GitHub link: [https://github.com/bitcoin/bips/pull/1500](https://github.com/bitcoin/bips/pull/1500).The BIP specifies the concept of a TxFieldSelector, which is a serialized data structure used to select data inside a transaction. It defines various global fields such as version, locktime, number of inputs, number of outputs, current input index, and current input control block. It also specifies the fields available for each input and output. Additionally, it introduces support for selecting inputs and outputs based on certain criteria, including all in/outputs, a single in/output at the same index as the input being executed, any number of leading in/outputs, and up to 64 individually selected in/outputs.The BIP introduces two new opcodes: OP_TXHASH and OP_CHECKTXHASHVERIFY. OP_TXHASH is enabled only in tapscript and takes a serialized TxFieldSelector from the stack and pushes on the stack a hash committing to all the selected data. OP_CHECKTXHASHVERIFY is enabled in all script contexts and expects a single item on the stack, interpreted as a 32-byte hash value concatenated with a serialized TxFieldSelector. Execution fails if the hash value in the data push doesn't match the calculated hash value based on the TxFieldSelector.The BIP also addresses concerns around resource usage, particularly related to quadratic hashing. It proposes a potential caching strategy to prevent excessive hashing. It limits individual selection to 64 items and suggests that selecting ""all"" in/outputs can mostly use the same caches as sighash calculations. It also mentions the possibility of storing intermediate SHA256 contexts for prefix hashing to minimize the number of items that need to be hashed repeatedly.The email discusses the achievements of this proposal. It mentions that the default TxFieldSelector is functionally equivalent to OP_CHECKTEMPLATEVERIFY, making it a strict upgrade of BIP-119. The flexibility of selecting transaction fields and in/outputs makes this construction more useful in designing protocols where users want to add fees to their transactions without breaking a transaction chain or when constructing transactions together with specific conditions on in/outputs. Additionally, OP_TXHASH, along with other opcodes like OP_CHECKSIGFROMSTACK, could be used as a replacement for complex sighash constructions.There are some open questions mentioned in the email. One question is whether the proposal sufficiently addresses concerns around resource usage and quadratic hashing. Another question relates to including the TxFieldSelector as part of the hash, which would affect the ability to prove equality of fields. A potential solution is suggested, which involves assigning additional bits in the ""in/output selector"" bytes to include the TxFieldSelector in the hash. The email also seeks general feedback on the proposal and whether it should be implemented as a softfork.In conclusion, Steven is seeking wider feedback and community interest in this proposal for a TxHash concept. He is willing to spend time formalizing the BIP and working on an implementation for Bitcoin Core if there is community interest.","['BIP', 'softfork', 'fees', 'SHA256']","['Transaction Hash', 'opcode', 'resource usage', 'sighash calculations', 'caching strategy', 'tapscript', 'TxHash', 'hashing', 'complex sighash constructions', 'TxFieldSelector', 'OP_CHECKTEMPLATEVERIFY', 'prefix hashing', 'transaction chain']"
SimLN: Simulate active test networks,"SimLN is a tool that simulates random payment activity on any test lightning network setup. It aims to make it easier to test applications and proposals against networks that are actively processing payments. The tool is set up agnostic and can run on any test environment such as local dev, signet, polar, and scaling lightning. To use SimLN, you need a network with open channels where you have execution access on some of the nodes, a config file that provides the simulator with node details, and the Rust compiler installed.SimLN allows you to configure specific payment flows, such as sending a specific amount from one node to another at regular intervals. Although it doesn't match the mainnet exactly, SimLN provides a tool for testing against ""busy"" networks, allowing more rigorous testing of changes and proposals. The random activity in SimLN is generated using two magic numbers: the capacity multiplier and the expected payment amount. The capacity multiplier represents how frequently a node sends its full balance/capacity over a calendar month, while the expected payment amount is the average payment amount in the network. The payment frequency is determined using an exponential distribution, similar to bitcoin block times. The payment destination is selected using a weighted uniform distribution based on node capacity, with larger nodes being more likely to be chosen. The payment amount is determined using a log normal distribution with the expected payment amount as the mean, introducing more varied payment sizes for larger nodes and less varied sizes for smaller nodes.While SimLN has some limitations, such as assigning the same capital efficiency to every node and biasing payments towards large nodes, it also offers several benefits. It saves time by automating payment generation and can be easily integrated into existing development environments. Additionally, it can produce NPC background noise for running tests specific to your work and make deploying to production less intimidating.Overall, SimLN provides a valuable tool for testing lightning network applications and proposals, allowing for more efficient and comprehensive testing in a simulated payment environment.","['Testing', 'Lightning']",[]
Scaling Lightning With Simple Covenants,"In the email, John discusses various aspects of Lightning network and channel resizing. He mentions that hierarchical channels can use HTLCs to send Lightning channel capacity over the Lightning network. This allows for off-chain channel resizing between channels that are not in the same pool.John also introduces a new version of the paper that includes a description of how to address the fragmentation costs imposed by a casual user going on-chain in a timeout-tree. The idea is to require casual users to reveal secrets (hash preimages) that only they know in order to put timeout-tree transactions on-chain. A fee-penalty output is then added to each leaf transaction to compensate the funder for the fragmentation costs.The new version of the paper also highlights the advantage of passive rollovers in eliminating the risk of HTLC-withholding attacks. Passive rollovers do not require the use of the Lightning network, thus reducing the on-chain footprint.Regarding the problem of reducing on-chain footprint in mass exit cases, John refers to ""short-cut"" transactions defined in Section 5.4 of the revised paper. These transactions propose a solution for addressing the logarithmic blow-up of putting a control transaction defined by a covenant tree on-chain.John clarifies that there is no case where multiple commitment transactions can spend an output from the same state transaction. Each user's state transaction can only be spent by their own commitment transaction. Furthermore, each commitment transaction at the hierarchical channel level requires signatures from all three users, ensuring that only the correct commitment transaction can spend the funding transaction output.In conclusion, the email covers various topics related to Lightning network, hierarchical channels, channel resizing, fragmentation costs, passive rollovers, HTLC-withholding attacks, and reducing on-chain footprint in mass exit cases. John provides insights and references to specific sections and figures in the revised version of the paper.","['Covenants', 'Lightning']","['on-chain footprint', 'HTLC-withholding attacks']"
Scaling Lightning With Simple Covenants,"The email discusses a tradeoff between trust and capital efficiency in the context of a single UTXO that is claimable by ""B"" at time T+L. The UTXO holds funds belonging not only to B, but also millions of casual users, C_1.C_1000000. If B cheats by not signing any further lightning updates between now and time T+L, each casual user needs to drop their channel to the chain or lose all their funds.This situation presents a ""thundering herd"" problem where instead of the expected one-in/one-out transaction, there would be between 1M and 2M on-chain transactions as everyone recovers their funds. The number of casual users multiplied by the factor that depends on how many outputs each internal transaction has determines the additional transactions. The impact of this additional transaction volume depends on the timeframe over which they are spread. If it's a day or two, it might be impossible to handle, but if it's over a year or more, it may not be noticeable. Somewhere in between, it could result in paying a modest amount in additional fees.To address this concern, casual users can calculate how many extra transactions per block their worst-case scenario generates. They can then determine when to ensure all their funds are rolled over to a new UTXO, considering the timeout period. This reduces B's capital efficiency since B will own all the funds in Fx for five months before accessing them. Each UTXO has an active lifetime (LA) and an inactive lifetime (LI = 5 months), which would have been used by everyone to recover their funds if B attempted to block normal rollover. The capital efficiency is reduced by a factor of 1/(1+LA/LI).Casual users cannot easily reduce their LI timeout by splitting into different UTXOs because if the provider cheats or fails, all participants across each UTXO will need to drop to the chain to preserve their funds, competing with each other for confirmation. Collusion among different providers can also cause problems as it increases the number of transactions significantly.The email then presents a scenario for a provider issuing a new UTXO every week and having a million casual users as customers. The provider targets an LA of 16 weeks (~3.5 months) and each user has a balanced channel with $2000 of their own funds and $2000 of the provider's funds. In this case, only 30% of the $6.5B worth of working capital dedicated to lightning is available for routing.Optimizing the LA does not necessarily work because if a casual user spends all their funds and disappears prior to the active lifetime running out, those funds cannot be easily spent by B until the total lifetime runs out. One possible solution to this is peering with a dedicated node and having a timeout path involving ""you+them+timeout."" This way, the funds can be rolled into a channel with the dedicated peer and used for routing.Varying the timeout at different layers of the internal tree is another option. For example, giving 500k users with a $10 balance a timeout of 16 weeks and giving the remaining 500k with an average $2000 balance a timeout of 26 weeks. Each group will calculate LI based on their timeout, and the rollover periods will vary accordingly. However, this may result in idle balances and should be carefully considered.Overall, the email raises concerns about what happens if the scalable path does not work and a large volume of transactions needs to be dumped on-chain. It suggests measuring and addressing this concern to ensure the smooth functioning of the system.","['Research', 'Hardware Wallet', 'Segwit', 'Lightning', 'Threshold Signatures', 'Script', 'Splicing', 'Smart Contracts', 'Hard Fork', 'Hashlocks', 'Security', 'Routing Failures', 'Mining', 'Soft Fork', 'Custody', 'Bech32', 'Merkle Trees', 'Stratum-V2', 'Musig', 'Sidechains', 'Topology', 'Forks', 'Fairness', 'Accumulators', 'Onion', 'Multiple-Path Payments', 'Signet', 'Miners', 'Build Systems', 'Consensus', 'Testing', 'Fee Management', 'Privacy', 'Eltoo', 'Taproot', 'Limitations', 'Scalability', 'Lnd', 'Miniscript', 'PSBT', 'Eclair', 'Ethereum', 'Sphinx', 'P2sh', 'Spv', 'Attacks', 'Validation', 'Cryptography', 'Covenants', 'Fungibility', 'Path-Finding', 'Wallet', 'Zero-Knowledge', 'Atomic Swaps', 'Timelocks', 'Academia', 'Fees', 'Update Layer', 'Halving', 'Pools', 'Regulation', 'Multisig', 'Submarine Swaps', 'Layer 2', 'Routing', 'C-Lightning', 'Proof-of-Work', 'P2pool', 'Ux']",['Incent']
Remotely control your lightning node from your favorite HSM,"The email discusses the use of runes in programming, specifically how they are often bound to the BOLT8 nodeid to protect them from being read. The author expresses a liking for this model but notes that it requires two-way communication for setup, where the Hardware Security Module (HSM) tells the node its id and the node gives the HSM the rune. However, the author mentions that supporting runes as an extension is easy and allows for experimentation. The email concludes with a mention of further discussion on a gist.","['Hardware Wallet', 'Lightning']",[]
Scaling Lightning With Simple Covenants,"The email discusses the start of a paper that the sender has been reading on their vacation. The sender mentions that even in the initial part of the paper, it presents some interesting possibilities. One point highlighted is that the cost of enforcement is significantly increased compared to other proposals. Instead of just one or two transactions, it now involves 10 or more. This raises the question of how much is enough when it comes to the expected fee contributed by the ""dedicated user"". Additionally, in the worst-case scenario of a dramatic failure by the dedicated user, there would only be a 2x penalty on the number of on-chain transactions, which may be acceptable if the network is mature enough and such failure events are rare.The email also mentions the surprisingly common case where the casual user fails to rollover, resulting in the funds being returned to the dedicated user. In this case, relying on legal and normal custody policies may be preferable to burdening the UTXO set indefinitely with the current approach. The email concludes with a thank you from the sender, Rusty.","['UTXO', 'Covenants', 'Fees']",[]
Scaling Lightning With Simple Covenants,"In the email, Antoine provides feedback on a proposal regarding the classification of users and the design of protocols. He points out that classifying users as ""casual"" or ""dedicated"" may not be straightforward, as trust assumptions in practice can be more nuanced. He gives examples of choices that users have in terms of block-relay, mempool size, routing HTLCs, and running local watchtowers. Antoine suggests that different scaling notions can be introduced to measure the performance of an off-chain construction, such as onboarding scaling, transactional scaling, and users resource scaling.Antoine mentions that the proposal mainly focuses on onboarding scalability, which involves maximizing the number of channels owned by a user. However, it is unclear if other scalability dimensions are taken into account. He questions the accuracy of a statement that no known protocol allows a large number of Lightning channels to be created from a single on-chain UTXO. He provides a link to a discussion on Bitcoin-dev mailing list that proposes a solution using a radixpool with Musig2.Antoine highlights the difficulty of coordinating a group of casual users to sign transactions specifying the exact set of users required. He identifies two specific problems related to group coordination: adding/removing users in a compact fashion and updating the channels owned by the users with minimal interactivity. He also raises concerns about the uncertainty of draining funds in a network where jamming is possible and the role of dedicated users in routing.Antoine points out that the requirement for casual users to perform actions at specific times in the future may be altered by the fact that there is no guarantee of timely on-chain transactions. He also mentions the potential challenges of immediately-accessible pre-signed/pre-committed transactions not propagating on the network due to mempool minimum fees.Finally, Antoine expresses uncertainty about the fault-tolerance of the off-chain construction, particularly if a user becomes unresponsive after a while, which could result in the entire construction being moved on-chain.Overall, Antoine provides detailed feedback and raises several important considerations regarding the proposal's classification of users, scalability dimensions, group coordination, routing challenges, and fault-tolerance.","['Lightning', 'Scalability', 'Routing', 'Covenants']",['Fault-tolerance']
Sidepools For Improving Payment Reliability At Scale,"In this email, the sender discusses the difficulty of predicting the future in terms of allocating liquidity on the Lightning Network. They compare allocating liquidity to investing in stocks and highlight the challenges of accurately predicting payment influxes and avoiding over or under-allocation.To address the issue of mis-allocating funds, the sender proposes the concept of sidepools. Sidepools are parallel constructions that allow forwarding node operators to manage the allocation of funds without closing channels. Instead of hosting channels within the sidepool mechanism, actual Lightning Network channels remain on-chain. The sidepool acts as a service for HTLC-swapping to facilitate the allocation of funds in the channels.The sender emphasizes the benefits of retaining 2-participant channels instead of expanding to channels with more participants. This approach reduces the number of participants who know about every payment, thus preserving privacy. Additionally, they mention that sidepools can be implemented using Decker-Wattenhofer decrementing `nSequence` mechanisms without any changes to Bitcoin.The motivation for using sidepools lies in their ability to help maintain liquidity in existing channels. By relying on other participants in the sidepool to receive funds, forwarding node operators can avoid depleting channels. This approach reduces costs compared to opening new channels or performing onchain/offchain swaps. The sender also acknowledges that past performance is not indicative of future performance, highlighting the potential risks of doubling down on specific counterparties.Another advantage of sidepools is their potential to support scaling by mitigating liquidity fluctuations during large buyer movements. The sender suggests the implementation of channel factories for end users and sidepools for forwarding nodes to further enhance scalability.Overall, the sender proposes the use of sidepools as a solution to the challenges of allocating liquidity on the Lightning Network. They provide insights into the benefits of this approach and how it can be implemented while maintaining compatibility with existing Lightning Network design.","['Privacy', 'Lightning', 'Scalability']","['Bitcoin', 'Channels']"
Bitcoin Research Day 2023,"The email announces the upcoming Bitcoin Research Day, which will take place at Chaincode in Midtown NYC on October 27th, 2023. The purpose of the event is to bring together researchers and developers to discuss the robustness, security, and decentralization of the Bitcoin system. The day will consist of both longer format talks, featuring speakers such as Benedikt BÃ¼nz, Ethan Heilman, Ittay Eyal, Carla Kirk-Cohen, Murch, and Martin Zumsande, among others, as well as lightning talks that will give researchers and developers the opportunity to present ongoing research and development projects in approximately five minutes.Slots for the lightning talks are still available, and interested individuals can sign up through the provided link (https://www.brd23.com/lightning-talks). The email encourages participation from both the bitcoin-dev and lightning-dev communities and invites anyone interested to attend and contribute to the discussion. The event is an in-person gathering, and attendees are required to RSVP through the website (https://www.brd23.com/).In summary, the email announces the Bitcoin Research Day, a conference that aims to bring together researchers and developers to discuss the robustness, security, and decentralization of the Bitcoin system. The event will feature longer format talks by notable speakers and lightning talks for shorter presentations of ongoing research and development projects. Interested individuals are encouraged to sign up for lightning talk slots and RSVP for the in-person event through the provided links.","['security', 'decentralization']","['lightning talks', 'lightning-dev communities', 'development projects', 'in-person gathering', 'ongoing research', 'RSVP', 'Bitcoin Research Day', 'researchers', 'longer format talks', 'developers', 'speakers', 'bitcoin-dev', 'Midtown NYC', 'October 27th, 2023', 'robustness', 'Chaincode']"
Announcing the Lightning Network Interoperability Initiative,"Vincent has written a documentation regarding his idea of the ""Lightning Network Interoperability Initiative."" The main objective of this initiative is to provide common tools that can be used for integration tests and stress testing the implementation to ensure compliance with the protocol and compatibility among different implementations. The goals of this initiative include crafting language-agnostic testing tools that facilitate various types of integration tests such as vertical, horizontal, and self integration testing. Vincent has already made significant progress in his experiment planning and results. He has developed tools like lnprototest, which is actively used in both the core lightning CI and his alpha stage lightning node written in ldk. For more detailed information about their aspirations, experiments, and implementation nuances, Vincent encourages readers to visit their documentation site. Vincent also welcomes feedback and collaborative efforts from the community. If anyone is interested in this idea or has any suggestions, they are encouraged to jump in and get involved.","['Lightning', 'Lightning-routing', 'Testing', 'Layer 2', 'C-Lightning']",[]
Scaling Lightning With Simple Covenants,"In this email, John agrees with aj's observation about the tradeoff between trust/safety and capital-efficiency. He suggests a solution where dedicated user B pairs with another dedicated user C, creating a hierarchical channel funded by the timeout-tree leaves. This idea is described in the ""Improving Capital Efficiency"" section of the post [1]. John acknowledges that passive rollovers complicate matters, but he proposes using aj's idea of funding an HTLC from one of two possible sources, where one source will eventually be available to them [2][3]. By using funds from the old and new timeout-trees that are not owned by A_i, B and C can route payments. Although hierarchical channels improve capital efficiency, John expresses concern about the ""thundering herd"" problem. He explains that casual users may become accustomed to larger timeout-trees without any issues. However, if a large number of dedicated users collude by not rolling over timeout-trees simultaneously, they can create congestion on the blockchain and steal a significant portion of the casual users' funds. To address this problem, John proposes a change to the Bitcoin consensus rules. Instead of timeout-trees expiring at a specific block height, they would expire only after a sufficient number of low-fee blocks have been added to the blockchain. This way, if dedicated users attempt to steal funds, the influx of transactions from casual users would raise fees and prevent the timeout-trees from expiring, safeguarding the casual users' funds. The consequence for the dedicated users would be longer unavailability of their capital, in addition to reputational damage.John mentions that he is currently writing a paper and post to describe this proposed change in detail. He provides a few additional details about the mechanism, such as measuring time in low-fee windows, programmable thresholds for low-fee blocks, a bound on waiting for low-fee windows to limit storage and compute overheads, and support for relative delays. He believes this mechanism will be useful in various areas, including HTLCs, but emphasizes that timeout-trees particularly highlight the need for such a solution [1].Please note that the farewell part of the email has been ignored as per the given instructions.","['Covenants', 'Bitcoin Core', 'Consensus', 'Lightning', 'Blockchain']",[]
Scaling Lightning With Simple Covenants,"In the email, Rusty and John are discussing an issue related to settling the channel on-chain and resolving HTLCS on-chain. They mention a paper that proposes using ""short-cut"" transactions to address the cost of enforcing HTLCs on-chain. This approach could potentially be applied to the channel itself, but it is more complex due to the value included in the channel and the possibility of having channels with different capacities in a single timeout-tree. The email ends with John expressing his agreement with Rusty's point.","['Lightning', 'Covenants']",[]
Scaling Lightning With Simple Covenants,"Summary:The email exchange between Antoine and John discusses various aspects of scalability and usability in Bitcoin. John emphasizes the importance of catering to casual users who simply want payments to work without the need for extensive time and hardware resources. He suggests providing multiple channels to accommodate these users.In terms of scalability, John praises Lightning for its ability to handle a large number of payments per channel without on-chain transactions. He also proposes the use of hierarchical channels, particularly in conjunction with timeout-trees, for effective off-chain resizing and changing pairings.While acknowledging the theoretical possibility of using signatures to create Lightning channels for a million casual users funded by a single UTXO, John believes it is not feasible in practice due to the challenge of getting all users to sign a transaction specifying the necessary signatories.Regarding active draining by casual users, John suggests that if the drain fails, the user should put their channel in the old timeout-tree on-chain to prevent it from timing out. However, he acknowledges that ideally, casual users would only need to perform actions when sending or receiving a payment, but finding a solution for this remains elusive.John agrees with the concern that users may not obtain bitcoin if they haven't signed and submitted a transaction with sufficient fees. He addresses this issue in the ""Limitations"" section of his post and plans to propose a timing mechanism based on fee levels as a potential solution.In cases where dedicated users funding a timeout-tree fail to rollover a casual user, the casual user should put their channel in the old timeout-tree on-chain. If this failure applies to all channels in the timeout-tree, the entire timeout-tree will be forced to go on-chain, potentially doubling the number of on-chain transactions.John also mentions the possibility of using zero-valued covenant trees and ""short-cut"" transactions to handle unresolved HTLCs off-chain and minimize the blow-up in on-chain transactions.Overall, the email exchange highlights John's proposals for improving scalability and usability in Bitcoin, particularly for casual users. He addresses various challenges and limitations while suggesting solutions and exploring different approaches.","['Lightning', 'Covenants']",['Scaling']
Scaling Lightning With Simple Covenants,"The email discusses a change in the trust model from a trustless one to a federated one, which results in an increased on-chain footprint of failure. The author seems to be questioning if this change is correct or not.","['Lightning', 'Covenants']",[]
Scaling Lightning With Simple Covenants,"Based on the email received, the main point discussed is the safety of user `B` creating something without a signature from user `A_i`. It is suggested that if the funding for the project comes solely from user `B`, it may not be safe unless user `A_i` provides a signature. The email mentions that if a specific user `A_i` never contacts user `B`, but still confirms the entire path from the funding transaction output to the `A_i && B` output, then the funds allocated by `B` are locked unless `B` receives a unilateral close signature from `A_i` to spend from the `A_i && B` output.The email emphasizes the need for `A_i` to be online when `B` signs the funding transaction that anchors the entire tree. It also mentions that many people lost funds when implementing `multifundchannel` because they didn't ensure that all counterparties in the same batch of openings had provided unilateral close signatures before broadcasting the funding transaction. Another alternative mentioned is to use a Spilman channel variant, where the leaf itself is infected with a lifetime `(A_i && B) || (B && CLTV)`. In this case, `B` can dedicate the leaf output to a separate transaction that spends from the `(A_i && B)` branch to a plain `A && B` Lightning channel. `B` can fund the tree and when `A_i` comes online and agrees to accept the channel from `B`, `A_i` creates two signatures: one for the transaction spending from `(A_i && B) || (B && CLTV)` to `A && B`, and another for the unilateral close transaction from the above output.Overall, the email discusses the importance of obtaining signatures from `A_i` for the safety of the project and highlights issues related to funding transactions and unilateral close signatures.","['Lightning', 'Covenants']",[]
Scaling Lightning With Simple Covenants,"MuSig and MuSig2 are both n-of-n signing algorithms, meaning that all entities in the set are required to sign. In the case of MuSig, this includes entities `A_i` for all `i` and a dedicated LN node `B`. The argument is that 2-of-2 channels are non-custodial and trust-minimized, and this extends to n-of-n for all values of n.","['Lightning', 'Covenants', 'MuSig']",[]
Sidepools For Improving Payment Reliability At Scale,"In the email, ZmnSCPxj discusses the implementation of a sidepool using the Decker-Wattenhofer mechanism. They mention that if this implementation is deployed with decrementing-nSequence mechanisms, several numbers need to be considered. These numbers include the number of stages, steps per stage, and blocks per step. However, ZmnSCPxj notes that these numbers have some limitations.The number of stages plus one represents the number of transactions that need to be confirmed in case of a unilateral close. The ""plus one"" is due to the ""kickoff transaction"" that initiates the unilateral close and starts the relative nSequence timers. Steps per stage raised to the number of stages represents the maximum number of updates possible. Once the mechanism saturates, an on-chain operation becomes necessary. This can be a ""no-op splice"" where the current funding txout is spent into a new funding txout with a refreshed mechanism starting from state 0.Blocks per step represents the maximum amount of time a participant can safely be offline during a unilateral close. If a participant is offline for longer than this period, other participants may present an older state where the offline participant has less money. The longest time a unilateral close can take is calculated by multiplying the number of stages, steps per stage minus 1, and blocks per step.ZmnSCPxj provides an example to illustrate these calculations. If number_of_stages is set to 8, steps_per_stage to 2, and blocks_per_step to 144 (1 day), then a unilateral close will lock up funds for a maximum of 8 days. Participants cannot be offline for longer than 144 blocks. The mechanism can support a maximum of 256 updates, and the number of swaps is half the number of updates.ZmnSCPxj also discusses the purpose of the sidepools mechanism, which is to provide another settlement layer on top of the blockchain layer. In case the channels become imbalanced, participants can initiate a ""swap party"" on the sidepool to move their imbalanced channels back to balance. During a swap party, participants offer HTLCs on the sidepool, which are then bundled into a single update. The channels put a ""reverse"" HTLC in the opposite direction, and the preimages are sent in the channel. Once the channel side HTLCs are fulfilled or failed, the claims and failures on the sidepool side can be bundled in a second update.After a swap party, the sidepool enters a ""moratorium"" period during which another swap party cannot be initiated. Alternatively, swap parties can be scheduled at fixed regular intervals, such as once per day at 00:00 UTC. ZmnSCPxj suggests that a 256-update mechanism can last for approximately 128 days, slightly more than 3 months. They consider this a reasonable deal compared to performing daily on-chain transactions for each channel that needs updating.Overall, ZmnSCPxj provides detailed information about implementing a sidepool using the Decker-Wattenhofer mechanism, including calculations for various numbers and the purpose of the sidepools mechanism in balancing channels.","['Consensus', 'Research', 'Sidechains', 'Lightning', 'Routing']",[]
"Practical PTLCs, a little more concretely","The email discusses the implementation of a new feature called PTLC (Point Time Lock Contract) in node software. The sender suggests starting with writing an optional BLIP (BOLT Improvement Proposal) as a way to roll out the feature. They mention that it would be best to focus on interop requirements such as routing gossip, onion messages, invoices, tx format, and peer messaging. These requirements involve making changes at a network/ecosystem-wide level. The sender emphasizes the importance of getting the first three requirements right as soon as possible, while the latter two can be renegotiated between peers without affecting others.The sender suggests picking something easy and pleasant to implement initially and optimizing it later. They provide a link to a GitHub pull request that describes how to do a single-signer adaptor using musig2. They believe this approach combines the benefits of a ""single-sig adaptor"" while utilizing the musig2 API. The sender also mentions the need to add or re-order peer messages when updating commitment transactions.In terms of efficiency, the sender believes the chosen approach should be comparable to HTLCs (Hash Time Lock Contracts) currently used. It should be relatively easy to think about and implement, and should not worsen the user experience due to a 1.5 round-trip time (RTT) forwarding delay.Once the initial implementation is working, the sender suggests adding feature flags for upgrading the single-sig adaptor to claimable via a musig2 double-sig key path, APO support (signing each PTLC once), 0.5 RTT fast-forwards, and supporting async updates. However, they advise deferring these additions unless the implementer is particularly enthusiastic about them, in order to keep things simple at the start.","['Lightning', 'Musig', 'Routing']",['Commitment Transactions']
"Practical PTLCs, a little more concretely","AJ,LL is seeking clarification on the distinction between a MuSig2 adaptor signature and a single-singer adaptor with MuSig2. It seems LL wants to understand the key differences between these two concepts. To provide some context, MuSig2 is a cryptographic protocol that allows multiple signers to create a single aggregated signature for a transaction. This helps improve privacy and efficiency in multi-signature schemes. An adaptor signature, on the other hand, is a type of signature that can be ""adapted"" or tweaked later without invalidating the original signature.Now, let's delve into the specific question raised by LL. A MuSig2 adaptor signature refers to a signature produced using the MuSig2 protocol, where the signer has the ability to adapt or modify the signature after it has been created. This means that even though the signature is initially valid, it can be altered later to produce a different signature that is also valid. The purpose behind this concept is to enhance flexibility in certain scenarios where signature adaptation is required.On the other hand, a single-singer adaptor with MuSig2 refers to a situation where only one signer is involved, but the MuSig2 protocol is still used. In this case, the signature is not intended to be adapted or modified after it has been created. The focus is on utilizing the MuSig2 protocol for achieving secure and efficient single-signer operations.It's worth noting that both concepts leverage the power of the MuSig2 protocol, which brings benefits such as improved security, privacy, and scalability to multi-signature schemes. However, the distinction lies in the ability to adapt the signature in the case of a MuSig2 adaptor signature, whereas a single-singer adaptor with MuSig2 does not involve such adaptation.I hope this clarifies the distinction between a MuSig2 adaptor signature and a single-singer adaptor with MuSig2. If you need further information or have any more questions, feel free to ask.Best regards,[Your Name]","['privacy', 'security', 'scalability']","['multi-signature schemes', 'cryptographic protocol', 'single-singer adaptor', 'signature adaptation', 'MuSig2', 'adaptor signature']"
"Practical PTLCs, a little more concretely","The email discusses the concept of performing Payment Channel Timelocked Contracts (PTLCs) scriptlessly. This can be achieved by using a 2-of-2 MuSig public key and an adaptor signature. The email mentions two approaches to achieve this: via the key path or via the script path.In the key path approach, nonce exchanges are required, leading to extra communication rounds. On the other hand, in the script path approach, the ""hash160 equalverify b checksig"" part in the script is replaced with ""a checksigverify b checksig"". Alice provides Bob with an adaptor signature, which Bob completes when claiming the output.The question raised in the email is how to implement the latter approach. The author suggests that it can be done by having Alice perform a ""single party musig2"" calculation, rather than needing a separate API.Overall, the email discusses the possibility of performing PTLCs scriptlessly using various approaches, and proposes a solution involving a 2-of-2 MuSig public key and an adaptor signature.","['Cryptography', 'MuSig', 'Script', 'Taproot']",[]
Announcing the Lightning Network Interoperability Initiative,"In a recent email, Vincent acknowledges an error in his previous post and provides the correct link. He apologizes for any confusion caused by the mistake. The correct link is not specified in the email, but it is mentioned that Vincent provided the correct link in a previous post.The email is brief and to the point, with no additional information or context provided. It is a simple clarification regarding the incorrect link shared in a previous post. Vincent signs off with a casual ""Cheers"" and his name.",['Lightning'],['Link']
"Practical PTLCs, a little more concretely",The email discusses a downside to using a MuSig API over a single key. The downside is that new people may question the use of the MuSig API and someone knowledgeable will have to explain the historical context and the specific APIs used in libsecp256k1 at that time. The downside mentioned is related to both performance and potential confusion among new users.,['libsecp256k1'],['MuSig API']
Payment Splitting & Switching and its impact on Balance Discovery Attacks (preprint),"Gijs van Dam begins the email by mentioning their previous discussion on Link MPP over alternative routes. They have developed a proof of concept called Payment Splitting & Switching (PSS) by creating a core-lightning plugin. The plugin works by splitting up a payment into multiple parts, with one part following the original route and using the original onion but committing to an HTLC with a lesser amount. Upon receiving this HTLC, the recipient can forward the payment but will wait for another payment from the sender. The sender then sends this additional payment over an alternative route, contingent on the payment hash of the original payment.The interest in Link MPP and PSS arises from Gijs van Dam's research on the Balance Discovery Attack (BDA), also known as the probing attack. PSS allows for route changes and amount changes without the sender's knowledge, which impacts how an attacker interprets information obtained through a BDA. In an LN simulator using real-world data, deploying PSS resulted in up to a 62% drop in information gain compared to earlier work without PSS. Further details on this research can be found in Gijs van Dam's preprint on the Cryptology ePrint Archive.Gijs van Dam welcomes feedback on their research and would like to hear thoughts on the role PSS could play in mitigating probing and/or jamming. They have also written a set of blog posts introducing the research, which can be found at the provided links. Finally, they mention that PSS may also work with PTLC, but this will be discussed at another time.Overall, the email discusses Gijs van Dam's development of the Payment Splitting & Switching (PSS) plugin, its potential applications in mitigating probing and/or jamming, and the impact of PSS on the Balance Discovery Attack (BDA). They provide links to additional resources for further reading and welcome feedback on their research.",[],"['Probing', 'Core-Lightning Plugin', 'PTLC', 'Balance Discovery Attack', 'Payment Splitting & Switching', 'Route Changes', 'LN Simulator', 'Information Gain', 'Jamming', 'Cryptology ePrint Archive', 'Amount Changes', 'Link MPP', 'Attacker']"
Scaling Lightning With Simple Covenants,"In an email sent by ZmnSCPxj to the recipient, Dave, the former refers to an alternative that is depicted in a diagram on page 6 and described in the text on page 7 of a paper. The email does not provide further details or context regarding this alternative.The email begins with a greeting - ""Good morning, ZmnSCPxj"" - followed by a statement indicating that the alternative being referred to is what is shown in the aforementioned diagram and described in the accompanying text. However, the exact nature or purpose of this alternative is not explicitly mentioned in the email.It is important to note that the email does not include any links or additional information that could provide further context or explanation. The tone of the email remains formal throughout, and there are no indications of any specific questions or requests from either party.Overall, the email appears to be a brief communication between ZmnSCPxj and Dave regarding the presence of an alternative in a paper, without delving into the specifics or implications of this alternative.","['Lightning', 'Covenants']",[]
Payment Splitting & Switching and its impact on Balance Discovery Attacks (preprint),"Gijs van Dam and Tony Giorgio are discussing a concept related to decorrelated payments. Gijs expresses his interest in the concept and mentions that it could potentially assist with decorrelated payments on an amount analysis level. He refers to the concept as a step up after having PTLC's (Presigned Transactional Lightning Contracts) and additional timing analysis protections. Gijs is curious if Tony sees this possibility based on a research write-up they did last year, which can be found at https://lightningprivacy.com/en/routing-analysissplintered-payments.",[],"['Payment Splitting', 'Balance Discovery Attacks']"
Scaling Lightning With Simple Covenants,"Antoine received an email from John discussing various aspects of off-chain constructions and their trade-offs. The email mentions that while many users want payments to work, they are not willing to invest time or hardware resources to make them work efficiently. Antoine agrees but points out that even casual users will have to store signatures and witnesses for off-chain balances somewhere. He suggests the use of hierarchical channels and timeout-trees to improve efficiency and scalability.The email also discusses the challenges of transactional scaling in Lightning Network due to liquidity imbalances among counterparties. Antoine mentions that on-chain splicing and pool rebalancing can help address this issue. He further explains that pre-committing a subset of casual or inactive users to sign transactions is not straightforward, especially for millions of users. A more efficient cryptographic accumulator would be needed in such cases.Antoine acknowledges that timeout-trees and channel resizing suffer from fault-tolerance issues when one user aims to go on-chain. The fragmentation cost is borne by all users in the tree branch. He highlights the importance of fault-tolerance and mentions that it is one of the key design goals for payment pool advancements.The concept of timevalue cost is also mentioned, where certain actions need to be performed within a limited time window. Antoine states that most off-chain constructions require strong liveliness and the ability to perform actions within a specific timeframe. He appreciates the TP-channel factories for allowing casual users to decide when they need to act.The thundering herd problem, which refers to a sudden surge of requests overwhelming a system, is discussed as a distinct issue in the original Lightning paper. Antoine agrees with this observation and points out that transaction-relay changes alone cannot fix this problem.Antoine raises concerns about dedicated users becoming targets for attacks, such as channel jamming or time-dilation, once they have multiple off-chain trees. He also mentions the possibility of using ""cut-through"" to reduce on-chain footprint in mass exit cases.Towards the end of the email, Antoine poses a few questions based on Dave's description of TP protocol, such as the prevention of double-spending and equivocation. He expresses his interest in understanding the security model of the TP protocol and how it compares to other off-chain constructions.Overall, the email discusses various aspects of off-chain constructions, their challenges, and potential solutions. Antoine acknowledges the insights shared by John and raises additional points for further exploration.","['Covenants', 'Lightning', 'Scalability']","['Cut-through', 'Channel jamming', 'Cryptographic accumulator', 'Equivocation', 'TP-channel factories', 'Thundering herd problem', 'Security model', 'Pool rebalancing', 'Transaction-relay changes', 'Timeout-trees', 'Time-dilation', 'Fault-tolerance', 'Double-spending', 'Timevalue cost', 'Off-chain constructions', 'Payment pool advancements']"
Scaling Lightning With Simple Covenants,"In an email exchange, the sender, John, acknowledges the recipient, ZmnSCPxj, for identifying an error in the design presented in a paper. John confirms that the figures in the paper and the accompanying descriptions accurately depict the design. However, he acknowledges that the quoted text provided by ZmnSCPxj is indeed incorrect and requires the suggested change. John informs ZmnSCPxj that he has created a new version of the paper [1], which incorporates this fix. Additionally, the revised version includes more detailed information on the utilization of hierarchical channels during passive rollovers, specifically mentioned at the end of Section 4.9. John expresses his gratitude to ZmnSCPxj for pointing out the correction. The email is signed off with John's regards and mentions that it was sent using Proton Mail secure email.","['Covenants', 'Lightning']",[]
Scaling Lightning With Simple Covenants,"John is responding to a previous email from Dave. He confirms that the figures and descriptions in the email are accurate, but there was an error in the initial text description. The email was sent using Proton Mail for added security.","['Covenants', 'Lightning']",[]
